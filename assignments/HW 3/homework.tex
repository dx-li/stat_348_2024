% to change the appearance of the header, questions, problems or subproblems, see the homework.cls file or
% override the \Problem, \Subproblem, \question or \printtitle commands.

% The hidequestions option hides the questions. Remove it to print the questions in the text.
\documentclass[hidequestions]{homework}
\usepackage{stat-macros}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{breqn}
\usepackage[shortlabels]{enumitem}
\usepackage{pdfpages}
\usepackage[colorlinks=true, urlcolor=blue, linkcolor=red]{hyperref}

% Set up your name, the course name and the homework set number.
\homeworksetup{
    username={Daniel Li},
    course={STAT 301},
    setnumber=7}
\begin{document}% this also prints the header.
%\includepdf[pages=-]{Q1.pdf}
% use starred problems or subproblems to apply manual numbering.
\problem
\subproblem 
\begin{align*}
    \mu\exp(-\mu x) = \exp(-\mu x + \log(\mu))\\
    h(x) = 1\\
    t(x) = x\\
    \eta = -\mu\\
    a(\eta) = -\log(-\eta)\\
\end{align*}
\begin{align*}
    \frac{b^a}{\Gamma(a)}x^{a-1}\exp(-bx) &= \exp(a\log(b) + (a-1)\log(x) - bx - \log(\Gamma(a)))\\
    h(x) = 1\\
    t(x) = \begin{bmatrix}
        \log(x)\\
        x
    \end{bmatrix}\\
    \eta = \begin{bmatrix}
        a-1\\
        -b
    \end{bmatrix}\\
    a(\eta) =  \log(\Gamma(\eta_1 + 1)) - (\eta_1 + 1)\log(-\eta_2)
\end{align*}
\subproblem
\begin{align*}
    P(\mu \g a,b) = \exp(a\log(b) + (a-1)\log(\mu) - b\mu - \log(\Gamma(a))) = \exp(- b\mu + (a-1)\log(\mu) + a\log(b) - \log(\Gamma(a)))
\end{align*}
and note that multiplying by $P(x \g \mu)$ preserves the form as only the $\mu$ terms are affected. Thus, the posterior is also a gamma distribution with parameters $a' = a + n$ and $b' = b + \sum_{i=1}^n x_i$.
\subproblem 
\begin{align*}
    P(\mu \g x_{1:n}, a, b) \propto \exp(- b\mu + (a-1)\log(\mu) + a\log(b) - \log(\Gamma(a)))\prod_{i=1}^n \exp(-\mu x_i + \log(\mu))\\
    \propto \exp(-\mu (b + \sum_{i=1}^n x_i) + (a + n - 1)\log(\mu) + (a\log(b) - \log(\Gamma(a))))\\
    P(\mu \g x_{1:n}, a, b) = \exp(-\mu (b + \sum_{i=1}^n x_i) + (a + n - 1)\log(\mu) + ((a+n)\log(b+ \sum_{i=1}^n x_i) - \log(\Gamma(a+n))))\\
\end{align*}
\subproblem 
\begin{align*}
    P(x_1 \g a,b) = \int P(x_1 \g \mu)P(\mu \g a,b)d\mu\\
     = \int \exp(-\mu x_1 + \log(\mu))\exp(- b\mu + (a-1)\log(\mu) + a\log(b) - \log(\Gamma(a)))d\mu\\
    = \exp( a\log(b) - \log(\Gamma(a))) \int \exp(-\mu(b + x_1) + a\log(\mu))d\mu\\
    = \exp( a\log(b) - \log(\Gamma(a))) \int \exp(-\mu(b + x_1) + a\log(\mu))d\mu\\
    = \frac{b^a}{\Gamma(a)} \int_0^\infty \mu^a \exp(-\mu(b + x_1)) d\mu\\
    = \frac{b^a}{\Gamma(a)} \frac{\Gamma(a+1)}{(x_1 + b)^{a+1}}\\
    = \frac{b^a a}{(x_1 + b)^{a+1}}
\end{align*}
\subproblem 
\begin{align*}
    P(x_{n+1} \g x_{1:n}, a, b) = \frac{(b + \sum_{i=1}^n x_i)^{a+n}}{\Gamma(a+n)} \int \mu^{a+n} \exp(-\mu(x_{n+1} + b + \sum_{i=1}^n x_i))d\mu\\
    = \frac{(b + \sum_{i=1}^n x_i)^{a+n}}{\Gamma(a+n)} \frac{\Gamma(a+n+1)}{(x_{n+1} + b + \sum_{i=1}^n x_i)^{a+n+1}}\\
    = \frac{(b + \sum_{i=1}^n x_i)^{a+n} (a+n)}{(x_{n+1} + b + \sum_{i=1}^n x_i)^{a+n+1}}
\end{align*}
\problem 
\subproblem 
\begin{align*}
    P(\mu \g x,a,b) \propto \frac{\mu^x}{x!}\exp(-\mu)\exp(a\log(b) + (a-1)\log(\mu) - b\mu - \log(\Gamma(a)))\\
    \propto \mu^{x + a -1} \exp(-\mu(b + 1))\\
    P(\mu \g x,a,b) = \frac{\mu^{x + a -1} \exp(-\mu(b + 1))(b+1)^{a+x}}{\Gamma(x + a)}
\end{align*}
\subproblem
\begin{align*}
    \frac{\mu^x}{x!}\exp(-\mu) = \frac{1}{x!}\exp(\log(\mu)x - \mu)\\
    h(x) = \frac{1}{x!}\\
    t(x) = x\\
    \eta = \log(\mu)\\
    a(\eta) = \exp(\eta)\\
\end{align*}
\begin{align*}
    \frac{\Gamma(x + r)}{x! \Gamma(r)}(1-p)^r p^x = \frac{\Gamma(x + r)}{x! \Gamma(r)}\exp(\log(p)x + r\log(1-p))\\
    h(x) = \frac{\Gamma(x + r)}{x! \Gamma(r)}\\
    t(x) = x\\
    \eta = \log(p)\\
    a(\eta) = -r\log(1-\exp(\eta))
\end{align*}
\subproblem
\begin{align*}
    \sum_{x \in \NN} \frac{1}{x!}\exp(\log(\mu_1)x - \mu_1) \log\left(\frac{\frac{1}{x!}\exp(\log(\mu_1)x - \mu_1)}{\frac{1}{x!}\exp(\log(\mu_2)x - \mu_2)}\right)\\
    =\sum_{x \in \NN} \frac{1}{x!}\exp(\log(\mu_1)x - \mu_1)(x\log(\frac{\mu_1}{\mu_2}) - \mu_1 + \mu_2)\\
    = \mu_1\log(\frac{\mu_1}{\mu_2}) - \mu_1 + \mu_2\\
\end{align*}
\subproblem
\begin{align*}
H(Pois(y) \g Gam(a,b))
    =\int_{0}^{\infty} -\sum_{x}^{\infty} \frac{y^x}{x!}e^{-y}\log(\frac{y^x}{x!}e^{-y})  d\text{Gam(a,b)}\\
    =\int_{0}^{\infty} -\sum_{x}^{\infty} \frac{y^x}{x!}e^{-y}\log(\frac{y^x}{x!}e^{-y})  d\text{Gam(a,b)}\\
    \leq  -\sum_{x}^{\infty} NB(x; a, \frac{1}{1+b}) \log(NB(x; a, \frac{1}{1+b}))\\
    = H(NB(x; a, \frac{1}{1+b}))
\end{align*}
Where we use Jensen's inequality on $f(t) = t\log(t)$.

\problem 
\subproblem 
\begin{align*}
    \argmax_k H(Z) - H(Z\g Y_k) &= \argmax_k H(Y_k) - H(Y_k \g Z)\\
    &= \argmax_k H(Y_k)\\
    &= \argmax_k H_2(\pi_k)\\
    &= \argmax_k \pi_k
\end{align*}
This works trivially when $K\leq2$ although the $K=2$ case is more of an arbitrary choice. Otherwise, the last line follows because the binary entropy is symmetrical about $0.5$ so we have the cases 1) where all $\pi_k < 0.5$ then the maximum is closest to 0.5 and 2) where there is one $\pi_j > 0.5$ and that is closest to 0.5 because every other $\pi_k$ is less than $1-\pi_j$.
\subproblem
\begin{align*}
    \argmax_k H(Z) - H(Z\g Y_k) = \argmax_k H(Y_k) - H(Y_k \g Z)\\
    = \argmax_k \left[-\pi_k q_k \log(\pi_k q_k) - (1-\pi_k q_k)\log(1-\pi_k q_k) \right] + 
    \pi_k(q_k \log(q_k) + (1-q_k)\log(1-q_k))\\
    = \argmax_k H_2(\pi_k q_k) + \pi_k H_2(q_k)\\
\end{align*}
\subproblem
\begin{table}[!h]
    \centering
    \begin{tabular}{lllll}
    pi            & 0.75       & 0.125      & 0.06125    & 0.06125    \\
    q             & 0.25       & 0.5        & 0.75       & 0.5        \\
                  &            &            &            &            \\
    H(Y)          & 0.69621226 & 0.33729007 & 0.26888241 & 0.19751658 \\
                  & 0.81127812 & 1          & 0.81127812 & 1          \\
    $H(Y|Z)$        & 0.60845859 & 0.125      & 0.04969079 & 0.06125    \\
                  &            &            &            &            \\
    H(Y) - $H(Y|Z)$ & 0.08775367 & 0.21229007 & 0.21919163 & 0.13626658
    \end{tabular}

    \end{table}
    $k^\star = 2$. It is not what I expected because of the low pi. But it makes sense in that there is more information in finding the submarine in a cell that you didn't expect it from. The relationshiop with SEPs and optimal search is that higher SEP means that the search is more likely to be successful so you would reduce your uncertainty by searching in the cells with higher SEP.
\end{document}